---
# yaml-language-server: $schema=https://raw.githubusercontent.com/fluxcd-community/flux2-schemas/main/helmrelease-helm-v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: &app comfyui
spec:
  interval: 30m
  chart:
    spec:
      chart: app-template
      version: 3.7.3
      sourceRef:
        kind: HelmRepository
        name: bjw-s
        namespace: flux-system

  install:
    remediation:
      retries: 3

  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
      strategy: rollback

  values:
    controllers:
      comfyui:
        type: statefulset

        annotations:
          reloader.stakater.com/auto: "true"

        pod:
          runtimeClassName: nvidia

          securityContext:
            runAsUser: 0
            runAsGroup: 0
            runAsNonRoot: false
            fsGroup: 1000
            fsGroupChangePolicy: OnRootMismatch

          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpressions:
                      - key: nvidia.com/gpu.present
                        operator: In
                        values:
                          - "true"

        containers:
          app:
            image:
              repository: vastai/comfy
              tag: cuda-12.8-auto@sha256:6d8bbfae6bbf7ee4c29b01a610be5369fc268c658a7dbba2cbe0ffdc2a4e3ef5
            # env:
            #   AUTO_UPDATE: "false"
            #   DIRECT_ADDRESS_GET_WAN: "true"
            #   SERVICEPORTAL_URL: "comfy.${SECRET_DOMAIN}"
            #   WEB_ENABLE_AUTH: "false"
            #   WORKSPACE: "/workspace"
            #   CF_QUICK_TUNNELS: "false"
            #   SERVERLESS: "false"
            #   PROVISIONING_SCRIPT: "https://raw.githubusercontent.com/ai-dock/comfyui/main/config/provisioning/flux.sh"

            securityContext:
              privileged: true

            resources:
              requests:
                cpu: 500m
                memory: 34Gi
              limits:
                memory: 34Gi
                nvidia.com/gpu: 1 # requesting 1 GPU

    service:
      app:
        controller: comfyui
        ports:
          http:
            port: 8188
          portal:
            port: 1111
          jupyter:
            port: 8080
          sync:
            port: 8384

    ingress:
      app:
        enabled: true
        className: internal
        annotations:
          hajimari.io/enable: "true"
          hajimari.io/appName: "ComfyUI"
          hajimari.io/icon: mdi:draw
          hajimari.io/group: "AI"
          hajimari.io/instance: "admin"
        hosts:
          - host: &host "comfy.${SECRET_DOMAIN}"
            paths:
              - path: /
                service:
                  identifier: app
                  port: http
              - path: /sync
                service:
                  identifier: app
                  port: sync
              - path: /portal
                service:
                  identifier: app
                  port: portal
              - path: /jupyter
                service:
                  identifier: app
                  port: jupyter
        tls:
          - hosts:
              - *host

    persistence:
      workspace:
        enabled: true
        existingClaim: comfyui
        globalMounts:
          - path: /workspace

      output:
        type: nfs
        server: tower.local
        path: /mnt/user/ai-output
        globalMounts:
          - path: /app/Output

      config:
        type: configMap
        name: comfyui-configmap
        advancedMounts:
          comfyui:
            app:
              - path: /workspace/ComfyUI/custom_nodes/ComfyUI-Manager/config.ini
                subPath: config.ini
                readOnly: true